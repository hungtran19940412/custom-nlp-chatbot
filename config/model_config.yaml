# Model configuration
model:
  base_model: bert-base-uncased
  num_labels: 5
  max_length: 512
  batch_size: 16
  learning_rate: 2e-5
  epochs: 3
  warmup_steps: 500
  weight_decay: 0.01

data:
  raw_path: data/raw/
  processed_path: data/processed/
  validation_split: 0.2
  test_split: 0.1

training:
  output_dir: models/fine_tuned_models/
  logging_dir: logs/training/
  save_steps: 500
  eval_steps: 500
  save_total_limit: 2
